{
    "GAE_lambda":0.95,
    "batch_size":32,
    "clip_reward":true,
    "entropy_coef":0.001,
    "epsilon":0.0005,
    "experience_memory_size":10000.0,
    "gamma":0.98,
    "learning_rate":0.001,
    "learning_step_thresh":10,
    "load_trained_model":true,
    "max_num_epsiodes":100000,
    "model_dir":"trained_models/",
    "num_agents":1,
    "policy_clip":0.02,
    "save_freq":20,
    "seed":2021,
    "summary_filename_prefix":"logs/PPO_",
    "use_cuda":true,
    "use_entropy_bonus":true
}
